import fs from "fs";
import path from "path";
import { promisify } from "util";
import cloudflareTransferService from "../services/cloudflareTransferService.js";
import { v4 as uuidv4 } from "uuid";

const readFileAsync = promisify(fs.readFile);

// Taille de chunk d√©finie √† 10Mo (minimum S3 multipart = 5MB)
export const CHUNK_SIZE = 10 * 1024 * 1024;

// Dossier temporaire local pour les chunks (fallback)
const TEMP_CHUNKS_DIR = path.join(
  process.cwd(),
  "public",
  "uploads",
  "temp-chunks"
);

/**
 * Sauvegarde un chunk de fichier sur Cloudflare R2
 * @param {Object} chunk - Le fichier chunk upload√©
 * @param {String} fileId - Identifiant unique du fichier
 * @param {Number} chunkIndex - Index du chunk
 * @param {String} fileName - Nom du fichier
 * @param {String} transferId - ID du transfert (optionnel, g√©n√©r√© si non fourni)
 * @returns {Promise<Object>} - Informations sur le chunk sauvegard√©
 */
export const saveChunkToR2 = async (
  chunk,
  fileId,
  chunkIndex,
  fileName,
  transferId = null
) => {
  try {
    const { createReadStream } = await chunk;
    const stream = createReadStream();

    // G√©n√©rer un transferId temporaire si non fourni
    if (!transferId) {
      transferId = `temp_${uuidv4()}`;
    }

    // Lire le stream en buffer
    const chunks = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    const chunkBuffer = Buffer.concat(chunks);

    console.log(
      `üì§ Sauvegarde chunk ${chunkIndex} pour fichier ${fileId} (${chunkBuffer.length} octets)`
    );

    // Upload du chunk vers R2
    const result = await cloudflareTransferService.uploadChunk(
      chunkBuffer,
      transferId,
      fileId,
      chunkIndex,
      fileName
    );

    return {
      chunkKey: result.key,
      chunkSize: result.size,
      chunkIndex,
      transferId,
    };
  } catch (error) {
    console.error(
      `Erreur lors de la sauvegarde du chunk ${chunkIndex} pour le fichier ${fileId}:`,
      error
    );
    throw error;
  }
};

/**
 * V√©rifie si tous les chunks d'un fichier ont √©t√© upload√©s sur R2
 * Utilise listObjects pour trouver les chunks quel que soit leur date d'upload
 * @param {String} transferId - ID du transfert
 * @param {String} fileId - Identifiant unique du fichier
 * @param {Number} totalChunks - Nombre total de chunks attendus
 * @returns {Promise<Boolean>} - True si tous les chunks sont pr√©sents
 */
export const areAllChunksReceivedOnR2 = async (
  transferId,
  fileId,
  totalChunks
) => {
  try {
    // Utiliser listObjects pour trouver tous les chunks
    const prefix = "temp/";
    const objects = await cloudflareTransferService.listObjects(prefix);

    // Filtrer les chunks correspondant au transferId et fileId
    const pattern = new RegExp(`t_${transferId}/f_${fileId}/chunk_(\\d+)`);
    const matchingChunks = objects.filter((obj) => pattern.test(obj.key));

    // V√©rifier si on a tous les chunks
    if (matchingChunks.length < totalChunks) {
      console.log(
        `‚ùå Chunks manquants pour fichier ${fileId}: ${matchingChunks.length}/${totalChunks}`
      );
      return false;
    }

    // V√©rifier que tous les indices de 0 √† totalChunks-1 sont pr√©sents
    const foundIndices = new Set();
    for (const obj of matchingChunks) {
      const match = obj.key.match(pattern);
      if (match) {
        foundIndices.add(parseInt(match[1], 10));
      }
    }

    for (let i = 0; i < totalChunks; i++) {
      if (!foundIndices.has(i)) {
        console.log(`‚ùå Chunk ${i} manquant pour fichier ${fileId}`);
        return false;
      }
    }

    console.log(
      `‚úÖ Tous les chunks (${totalChunks}) pr√©sents pour fichier ${fileId}`
    );
    return true;
  } catch (error) {
    console.error(
      `Erreur lors de la v√©rification des chunks pour ${fileId}:`,
      error
    );
    return false;
  }
};

/**
 * Reconstruit un fichier complet √† partir de ses chunks sur R2
 * @param {String} transferId - ID du transfert
 * @param {String} fileId - Identifiant unique du fichier
 * @param {String} fileName - Nom du fichier
 * @param {Number} totalChunks - Nombre total de chunks
 * @param {String} mimeType - Type MIME du fichier
 * @returns {Promise<Object>} - Informations sur le fichier reconstruit
 */
export const reconstructFileFromR2 = async (
  transferId,
  fileId,
  fileName,
  totalChunks,
  mimeType
) => {
  try {
    console.log(
      `üîß Reconstruction du fichier ${fileName} (${fileId}) √† partir de ${totalChunks} chunks`
    );

    // D√©terminer le type MIME si non fourni
    if (!mimeType) {
      const ext = path.extname(fileName).toLowerCase();
      mimeType = cloudflareTransferService.getContentType(ext);
    }

    // Reconstruire le fichier sur R2
    const result = await cloudflareTransferService.reconstructFileFromChunks(
      transferId,
      fileId,
      fileName,
      totalChunks,
      mimeType
    );

    console.log(
      `‚úÖ Fichier reconstruit: ${result.key} (${result.size} octets)`
    );

    // ‚úÖ CORRECTION #2: S√©parer le nom original (sans ID) du nom de stockage (avec ID)
    // originalName et displayName = nom propre pour l'utilisateur
    // fileName = nom avec ID pour l'unicit√© en stockage (mais non utilis√© pour le t√©l√©chargement)
    const sanitizedFileName =
      cloudflareTransferService.sanitizeFileName(fileName);

    // Retourner les informations du fichier dans le format attendu
    return {
      originalName: fileName, // Nom original sans ID (utilis√© pour le t√©l√©chargement)
      displayName: fileName, // Nom affich√© √† l'utilisateur (sans ID)
      fileName: `${fileId}_${sanitizedFileName}`, // Nom de stockage avec ID (pour unicit√©)
      filePath: result.url, // URL d'acc√®s au fichier
      r2Key: result.key, // Cl√© R2 pour r√©f√©rence
      mimeType: result.contentType,
      size: result.size,
      storageType: "r2", // Indicateur du type de stockage
    };
  } catch (error) {
    console.error(
      `Erreur lors de la reconstruction du fichier ${fileId}:`,
      error
    );
    throw error;
  }
};

/**
 * Nettoie les chunks temporaires d'un fichier en cas d'erreur
 * @param {String} transferId - ID du transfert
 * @param {String} fileId - Identifiant unique du fichier
 * @param {Number} totalChunks - Nombre total de chunks
 * @returns {Promise<Boolean>} - True si le nettoyage a r√©ussi
 */
export const cleanupChunksFromR2 = async (transferId, fileId, totalChunks) => {
  try {
    console.log(`üßπ Nettoyage des chunks pour fichier ${fileId}`);

    await cloudflareTransferService.cleanupChunks(
      transferId,
      fileId,
      totalChunks
    );

    console.log(`‚úÖ Nettoyage termin√© pour fichier ${fileId}`);
    return true;
  } catch (error) {
    console.error(
      `Erreur lors du nettoyage des chunks pour le fichier ${fileId}:`,
      error
    );
    return false;
  }
};

/**
 * Upload direct d'un fichier complet vers R2 (sans chunks)
 * @param {Object} file - Fichier upload√©
 * @param {String} transferId - ID du transfert
 * @param {String} fileId - ID du fichier
 * @returns {Promise<Object>} - Informations sur le fichier upload√©
 */
export const uploadFileDirectToR2 = async (file, transferId, fileId) => {
  try {
    const { createReadStream, filename, mimetype } = await file;
    const stream = createReadStream();

    // Lire le stream en buffer
    const chunks = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    const fileBuffer = Buffer.concat(chunks);

    console.log(
      `üì§ Upload direct du fichier ${filename} (${fileBuffer.length} octets)`
    );

    // V√©rifier la taille du fichier
    if (!cloudflareTransferService.isValidFileSize(fileBuffer)) {
      throw new Error("Fichier trop volumineux (limite: 10GB)");
    }

    // Upload vers R2
    const result = await cloudflareTransferService.uploadFile(
      fileBuffer,
      transferId,
      fileId,
      filename,
      mimetype
    );

    return {
      originalName: filename,
      displayName: filename,
      fileName: `${fileId}_${cloudflareTransferService.sanitizeFileName(
        filename
      )}`,
      filePath: result.url,
      r2Key: result.key,
      mimeType: result.contentType,
      size: result.size,
      storageType: "r2",
    };
  } catch (error) {
    console.error("Erreur lors de l'upload direct vers R2:", error);
    throw error;
  }
};

/**
 * Upload d'un fichier base64 vers R2
 * @param {Object} fileInput - Donn√©es du fichier en base64
 * @param {String} transferId - ID du transfert
 * @param {String} fileId - ID du fichier
 * @returns {Promise<Object>} - Informations sur le fichier upload√©
 */
export const uploadBase64FileToR2 = async (fileInput, transferId, fileId) => {
  try {
    const { name, type, size, base64 } = fileInput;

    console.log(
      `üì§ Upload base64 du fichier ${name} (taille d√©clar√©e: ${size})`
    );

    // D√©coder le base64
    let base64Data = "";
    let contentType = type;

    // V√©rifier si la cha√Æne contient un en-t√™te data URI
    if (base64.includes(";base64,")) {
      const parts = base64.split(";base64,");
      contentType = parts[0].replace("data:", "");
      base64Data = parts[1];
    } else if (base64.startsWith("data:") && base64.includes(",")) {
      const parts = base64.split(",");
      contentType = parts[0].replace("data:", "").replace(";", "");
      base64Data = parts[1];
    } else {
      base64Data = base64;
    }

    // Nettoyer la cha√Æne base64
    base64Data = base64Data.replace(/\s/g, "");

    // V√©rifier la validit√© du base64
    const base64Regex = /^[A-Za-z0-9+/=]+$/;
    if (!base64Regex.test(base64Data)) {
      throw new Error("Cha√Æne base64 invalide");
    }

    // D√©coder en buffer
    const fileBuffer = Buffer.from(base64Data, "base64");

    console.log(`üìä Fichier d√©cod√©: ${fileBuffer.length} octets`);

    // V√©rifier la taille du fichier
    if (!cloudflareTransferService.isValidFileSize(fileBuffer)) {
      throw new Error("Fichier trop volumineux (limite: 10GB)");
    }

    // Upload vers R2
    const result = await cloudflareTransferService.uploadFile(
      fileBuffer,
      transferId,
      fileId,
      name,
      contentType
    );

    return {
      originalName: name,
      displayName: name,
      fileName: `${fileId}_${cloudflareTransferService.sanitizeFileName(name)}`,
      filePath: result.url,
      r2Key: result.key,
      mimeType: result.contentType,
      size: result.size,
      storageType: "r2",
    };
  } catch (error) {
    console.error("Erreur lors de l'upload base64 vers R2:", error);
    throw error;
  }
};

/**
 * Supprime un fichier de R2
 * @param {String} r2Key - Cl√© R2 du fichier
 * @returns {Promise<Boolean>} - True si la suppression a r√©ussi
 */
export const deleteFileFromR2 = async (r2Key) => {
  try {
    if (!r2Key) {
      console.warn("‚ö†Ô∏è Cl√© R2 manquante pour la suppression");
      return false;
    }

    await cloudflareTransferService.deleteFile(r2Key);
    console.log(`üóëÔ∏è Fichier supprim√© de R2: ${r2Key}`);
    return true;
  } catch (error) {
    console.error(
      `Erreur lors de la suppression du fichier R2 ${r2Key}:`,
      error
    );
    return false;
  }
};

/**
 * G√©n√®re une URL d'acc√®s temporaire pour un fichier R2
 * @param {String} r2Key - Cl√© R2 du fichier
 * @param {Number} expiresIn - Dur√©e de validit√© en secondes
 * @returns {Promise<String>} - URL d'acc√®s temporaire
 */
export const generateFileAccessUrl = async (r2Key, expiresIn = 3600) => {
  try {
    if (!r2Key) {
      throw new Error("Cl√© R2 manquante");
    }

    return await cloudflareTransferService.getFileUrl(r2Key, expiresIn);
  } catch (error) {
    console.error(
      `Erreur lors de la g√©n√©ration de l'URL d'acc√®s pour ${r2Key}:`,
      error
    );
    throw error;
  }
};
