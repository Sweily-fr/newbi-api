#!/usr/bin/env node

/**
 * Script de sauvegarde compl√®te de la base de donn√©es de production
 * 
 * Ce script :
 * 1. Cr√©e une sauvegarde compl√®te de la base de donn√©es MongoDB
 * 2. Exporte toutes les collections avec leurs donn√©es
 * 3. G√©n√®re un fichier de sauvegarde horodat√©
 * 4. Valide l'int√©grit√© de la sauvegarde
 * 
 * Usage: node scripts/backup-production-db.js [--output-dir=/path/to/backup]
 */

import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import path from 'path';
import dotenv from 'dotenv';
import { fileURLToPath } from 'url';
import { dirname } from 'path';

const execAsync = promisify(exec);

// Configuration ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// Fonction pour charger les variables d'environnement depuis ecosystem.config.cjs
async function loadEcosystemConfig() {
  const ecosystemPath = path.resolve(__dirname, '../ecosystem.config.cjs');
  
  try {
    await fs.access(ecosystemPath);
    console.log('üìÑ Chargement des variables depuis ecosystem.config.cjs');
    
    // Importer dynamiquement le fichier ecosystem
    const ecosystemConfig = await import(`file://${ecosystemPath}`);
    const config = ecosystemConfig.default;
    
    if (config && config.apps && config.apps[0] && config.apps[0].env) {
      // Appliquer les variables d'environnement
      Object.assign(process.env, config.apps[0].env);
      
      // Si env_production existe, l'utiliser aussi
      if (config.apps[0].env_production) {
        Object.assign(process.env, config.apps[0].env_production);
      }
      
      console.log('‚úÖ Variables d\'environnement charg√©es depuis ecosystem.config.cjs');
      return true;
    }
  } catch (error) {
    console.log('‚ö†Ô∏è  Impossible de charger ecosystem.config.cjs:', error.message);
  }
  
  return false;
}

// Charger les variables d'environnement
dotenv.config();
await loadEcosystemConfig();

// Param√®tres du script
const OUTPUT_DIR = process.argv.find(arg => arg.startsWith('--output-dir='))?.split('=')[1] || './backups';
const TIMESTAMP = new Date().toISOString().replace(/[:.]/g, '-').split('T')[0] + '_' + new Date().toISOString().replace(/[:.]/g, '-').split('T')[1].split('.')[0];

/**
 * Extrait les informations de connexion MongoDB depuis l'URI
 */
function parseMongoUri(uri) {
  const url = new URL(uri);
  return {
    host: url.hostname,
    port: url.port || '27017',
    database: url.pathname.slice(1),
    username: url.username,
    password: url.password,
    authSource: url.searchParams.get('authSource') || url.pathname.slice(1),
    // Ajouter support pour les param√®tres SSL/TLS
    ssl: url.searchParams.get('ssl') === 'true',
    authMechanism: url.searchParams.get('authMechanism')
  };
}

/**
 * Cr√©e le r√©pertoire de sauvegarde
 */
async function createBackupDirectory() {
  const backupDir = path.resolve(OUTPUT_DIR, `backup_${TIMESTAMP}`);
  
  try {
    await fs.mkdir(backupDir, { recursive: true });
    console.log(`üìÅ R√©pertoire de sauvegarde cr√©√©: ${backupDir}`);
    return backupDir;
  } catch (error) {
    throw new Error(`Impossible de cr√©er le r√©pertoire de sauvegarde: ${error.message}`);
  }
}

/**
 * Effectue la sauvegarde avec mongodump
 */
async function performMongoDump(backupDir) {
  console.log('üîÑ D√©marrage de la sauvegarde MongoDB...');
  
  const mongoUri = process.env.MONGODB_URI;
  if (!mongoUri) {
    throw new Error('MONGODB_URI non d√©fini dans les variables d\'environnement');
  }
  
  console.log(`üîó URI MongoDB d√©tect√©: ${mongoUri.replace(/\/\/[^:]+:[^@]+@/, '//***:***@')}`);
  
  // Construction de la commande mongodump avec URI compl√®te
  let mongodumpCmd = `mongodump --uri="${mongoUri}" --out="${backupDir}" --gzip`;
  
  console.log('üì¶ Ex√©cution de mongodump...');
  console.log(`Commande: mongodump --uri="***" --out="${backupDir}" --gzip`);
  
  try {
    const { stdout, stderr } = await execAsync(mongodumpCmd);
    
    if (stderr && !stderr.includes('done dumping')) {
      console.warn('‚ö†Ô∏è  Avertissements mongodump:', stderr);
    }
    
    console.log('‚úÖ Sauvegarde mongodump termin√©e');
    
    // Extraire le nom de la base pour retourner le bon chemin
    const mongoInfo = parseMongoUri(mongoUri);
    return path.join(backupDir, mongoInfo.database);
    
  } catch (error) {
    throw new Error(`Erreur lors de l'ex√©cution de mongodump: ${error.message}`);
  }
}

/**
 * Cr√©e un export JSON des collections critiques
 */
async function exportCriticalCollections(backupDir) {
  console.log('üìã Export des collections critiques en JSON...');
  
  const mongoUri = process.env.MONGODB_URI;
  const mongoInfo = parseMongoUri(mongoUri);
  
  // Collections critiques √† exporter en JSON pour faciliter l'inspection
  const criticalCollections = [
    'Users', // Ancienne collection
    'user',  // Nouvelle collection
    'invoices',
    'quotes',
    'expenses',
    'clients'
  ];
  
  const jsonDir = path.join(backupDir, 'json_exports');
  await fs.mkdir(jsonDir, { recursive: true });
  
  for (const collection of criticalCollections) {
    try {
      let mongoexportCmd = `mongoexport`;
      
      if (mongoInfo.host !== 'localhost') {
        mongoexportCmd += ` --host "${mongoInfo.host}:${mongoInfo.port}"`;
      }
      
      if (mongoInfo.username && mongoInfo.password) {
        mongoexportCmd += ` --username "${mongoInfo.username}" --password "${mongoInfo.password}"`;
        mongoexportCmd += ` --authenticationDatabase "${mongoInfo.authSource}"`;
      }
      
      mongoexportCmd += ` --db "${mongoInfo.database}"`;
      mongoexportCmd += ` --collection "${collection}"`;
      mongoexportCmd += ` --out "${path.join(jsonDir, `${collection}.json`)}"`;
      mongoexportCmd += ` --pretty`;
      
      const { stdout, stderr } = await execAsync(mongoexportCmd);
      
      if (stderr && !stderr.includes('exported')) {
        console.warn(`‚ö†Ô∏è  Avertissement pour ${collection}:`, stderr);
      } else {
        console.log(`‚úÖ Collection ${collection} export√©e`);
      }
      
    } catch (error) {
      console.warn(`‚ö†Ô∏è  Impossible d'exporter ${collection}: ${error.message}`);
    }
  }
}

/**
 * G√©n√®re un rapport de sauvegarde
 */
async function generateBackupReport(backupDir) {
  console.log('üìä G√©n√©ration du rapport de sauvegarde...');
  
  const reportPath = path.join(backupDir, 'backup_report.txt');
  const mongoUri = process.env.MONGODB_URI;
  const mongoInfo = parseMongoUri(mongoUri);
  
  let report = `RAPPORT DE SAUVEGARDE NEWBI
========================================
Date: ${new Date().toISOString()}
Base de donn√©es: ${mongoInfo.database}
Serveur: ${mongoInfo.host}:${mongoInfo.port}
R√©pertoire: ${backupDir}

CONTENU DE LA SAUVEGARDE:
`;

  try {
    // Lister les fichiers de sauvegarde
    const files = await fs.readdir(backupDir, { recursive: true });
    
    report += `\nFichiers cr√©√©s:\n`;
    for (const file of files) {
      const filePath = path.join(backupDir, file);
      try {
        const stats = await fs.stat(filePath);
        if (stats.isFile()) {
          report += `- ${file} (${Math.round(stats.size / 1024)} KB)\n`;
        }
      } catch (error) {
        report += `- ${file} (erreur lecture)\n`;
      }
    }
    
    // Informations sur les collections JSON
    const jsonDir = path.join(backupDir, 'json_exports');
    try {
      const jsonFiles = await fs.readdir(jsonDir);
      report += `\nExports JSON:\n`;
      for (const jsonFile of jsonFiles) {
        const jsonPath = path.join(jsonDir, jsonFile);
        const content = await fs.readFile(jsonPath, 'utf8');
        const lines = content.split('\n').filter(line => line.trim()).length;
        report += `- ${jsonFile}: ${lines} documents\n`;
      }
    } catch (error) {
      report += `\nErreur lecture exports JSON: ${error.message}\n`;
    }
    
  } catch (error) {
    report += `\nErreur g√©n√©ration rapport: ${error.message}\n`;
  }
  
  report += `\nSauvegarde termin√©e √†: ${new Date().toISOString()}\n`;
  
  await fs.writeFile(reportPath, report, 'utf8');
  console.log(`üìÑ Rapport sauvegard√©: ${reportPath}`);
  
  return report;
}

/**
 * Valide l'int√©grit√© de la sauvegarde
 */
async function validateBackup(backupDir) {
  console.log('üîç Validation de l\'int√©grit√© de la sauvegarde...');
  
  const mongoUri = process.env.MONGODB_URI;
  const mongoInfo = parseMongoUri(mongoUri);
  const dumpDir = path.join(backupDir, mongoInfo.database);
  
  try {
    // V√©rifier que le r√©pertoire de dump existe
    const dumpStats = await fs.stat(dumpDir);
    if (!dumpStats.isDirectory()) {
      throw new Error('R√©pertoire de dump non trouv√©');
    }
    
    // Lister les fichiers BSON
    const files = await fs.readdir(dumpDir);
    const bsonFiles = files.filter(f => f.endsWith('.bson.gz') || f.endsWith('.bson'));
    
    if (bsonFiles.length === 0) {
      throw new Error('Aucun fichier BSON trouv√© dans la sauvegarde');
    }
    
    console.log(`‚úÖ Validation r√©ussie: ${bsonFiles.length} collections sauvegard√©es`);
    
    // Afficher les collections sauvegard√©es
    console.log('üìã Collections sauvegard√©es:');
    for (const file of bsonFiles) {
      const collectionName = file.replace('.bson.gz', '').replace('.bson', '');
      const filePath = path.join(dumpDir, file);
      const stats = await fs.stat(filePath);
      console.log(`  - ${collectionName} (${Math.round(stats.size / 1024)} KB)`);
    }
    
    return true;
    
  } catch (error) {
    console.error('‚ùå Validation √©chou√©e:', error.message);
    return false;
  }
}

/**
 * Fonction principale
 */
async function main() {
  const startTime = Date.now();
  
  try {
    console.log('üöÄ D√âMARRAGE DE LA SAUVEGARDE DE PRODUCTION');
    console.log(`Timestamp: ${TIMESTAMP}`);
    console.log(`R√©pertoire de sortie: ${OUTPUT_DIR}`);
    console.log('=' .repeat(60));
    
    // V√©rifier que mongodump est disponible
    try {
      await execAsync('mongodump --version');
    } catch (error) {
      throw new Error('mongodump n\'est pas install√© ou accessible. Installez MongoDB Database Tools.');
    }
    
    // √âtape 1: Cr√©er le r√©pertoire de sauvegarde
    const backupDir = await createBackupDirectory();
    
    // √âtape 2: Effectuer la sauvegarde mongodump
    await performMongoDump(backupDir);
    
    // √âtape 3: Exporter les collections critiques en JSON
    await exportCriticalCollections(backupDir);
    
    // √âtape 4: Valider la sauvegarde
    const isValid = await validateBackup(backupDir);
    if (!isValid) {
      throw new Error('La validation de la sauvegarde a √©chou√©');
    }
    
    // √âtape 5: G√©n√©rer le rapport
    const report = await generateBackupReport(backupDir);
    
    const duration = Math.round((Date.now() - startTime) / 1000);
    
    console.log('\nüéâ SAUVEGARDE TERMIN√âE AVEC SUCC√àS');
    console.log(`‚è±Ô∏è  Dur√©e: ${duration} secondes`);
    console.log(`üìÅ Emplacement: ${backupDir}`);
    console.log('\nüìã R√âSUM√â:');
    console.log(report.split('CONTENU DE LA SAUVEGARDE:')[1] || 'Rapport non disponible');
    
    console.log('\n‚ö†Ô∏è  IMPORTANT:');
    console.log('- V√©rifiez que la sauvegarde est compl√®te avant de proc√©der √† la migration');
    console.log('- Conservez cette sauvegarde jusqu\'√† validation compl√®te de la migration');
    console.log('- Testez la restauration sur un environnement de test si possible');
    
  } catch (error) {
    console.error('‚ùå ERREUR FATALE:', error.message);
    console.error(error.stack);
    process.exit(1);
  }
}

// Ex√©cution du script
if (import.meta.url === `file://${process.argv[1]}`) {
  main();
}

export { main as backupProductionDb };
